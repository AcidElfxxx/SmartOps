{"ast":null,"code":"import _slicedToArray from\"C:/Users/ASUS/PycharmProjects/SmartOps/django-test/frontend/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";import React,{useEffect,useState}from'react';import{jsx as _jsx}from\"react/jsx-runtime\";var SpeechToText=function SpeechToText(){var _useState=useState(''),_useState2=_slicedToArray(_useState,2),transcription=_useState2[0],setTranscription=_useState2[1];useEffect(function(){var recognition=new window.SpeechRecognition();recognition.interimResults=true;recognition.lang='en-US';recognition.addEventListener('result',function(event){var interimTranscript='';for(var i=event.resultIndex;i<event.results.length;i++){var transcript=event.results[i][0].transcript;if(event.results[i].isFinal){setTranscription(transcript);}else{interimTranscript+=transcript;}}setTranscription(interimTranscript);});recognition.start();return function(){recognition.abort();};},[]);return/*#__PURE__*/_jsx(\"div\",{children:/*#__PURE__*/_jsx(\"p\",{children:transcription})});};export default SpeechToText;","map":{"version":3,"names":["React","useEffect","useState","SpeechToText","transcription","setTranscription","recognition","window","SpeechRecognition","interimResults","lang","addEventListener","event","interimTranscript","i","resultIndex","results","length","transcript","isFinal","start","abort"],"sources":["C:/Users/ASUS/PycharmProjects/SmartOps/django-test/frontend/src/components/Home/SpeechToText.js"],"sourcesContent":["import React, { useEffect, useState } from 'react';\r\n\r\nconst SpeechToText = () => {\r\n    const [transcription, setTranscription] = useState('');\r\n\r\n    useEffect(() => {\r\n        const recognition = new window.SpeechRecognition();\r\n        recognition.interimResults = true;\r\n        recognition.lang = 'en-US';\r\n\r\n        recognition.addEventListener('result', (event) => {\r\n            let interimTranscript = '';\r\n            for (let i = event.resultIndex; i < event.results.length; i++) {\r\n                const transcript = event.results[i][0].transcript;\r\n                if (event.results[i].isFinal) {\r\n                    setTranscription(transcript);\r\n                } else {\r\n                    interimTranscript += transcript;\r\n                }\r\n            }\r\n            setTranscription(interimTranscript);\r\n        });\r\n\r\n        recognition.start();\r\n\r\n        return () => {\r\n            recognition.abort();\r\n        };\r\n    }, []);\r\n\r\n    return (\r\n        <div>\r\n            <p>{transcription}</p>\r\n        </div>\r\n    );\r\n};\r\n\r\nexport default SpeechToText;\r\n"],"mappings":"iJAAA,MAAOA,MAAK,EAAIC,SAAS,CAAEC,QAAQ,KAAQ,OAAO,CAAC,2CAEnD,GAAMC,aAAY,CAAG,QAAfA,aAAY,EAAS,CACvB,cAA0CD,QAAQ,CAAC,EAAE,CAAC,wCAA/CE,aAAa,eAAEC,gBAAgB,eAEtCJ,SAAS,CAAC,UAAM,CACZ,GAAMK,YAAW,CAAG,GAAIC,OAAM,CAACC,iBAAiB,EAAE,CAClDF,WAAW,CAACG,cAAc,CAAG,IAAI,CACjCH,WAAW,CAACI,IAAI,CAAG,OAAO,CAE1BJ,WAAW,CAACK,gBAAgB,CAAC,QAAQ,CAAE,SAACC,KAAK,CAAK,CAC9C,GAAIC,kBAAiB,CAAG,EAAE,CAC1B,IAAK,GAAIC,EAAC,CAAGF,KAAK,CAACG,WAAW,CAAED,CAAC,CAAGF,KAAK,CAACI,OAAO,CAACC,MAAM,CAAEH,CAAC,EAAE,CAAE,CAC3D,GAAMI,WAAU,CAAGN,KAAK,CAACI,OAAO,CAACF,CAAC,CAAC,CAAC,CAAC,CAAC,CAACI,UAAU,CACjD,GAAIN,KAAK,CAACI,OAAO,CAACF,CAAC,CAAC,CAACK,OAAO,CAAE,CAC1Bd,gBAAgB,CAACa,UAAU,CAAC,CAChC,CAAC,IAAM,CACHL,iBAAiB,EAAIK,UAAU,CACnC,CACJ,CACAb,gBAAgB,CAACQ,iBAAiB,CAAC,CACvC,CAAC,CAAC,CAEFP,WAAW,CAACc,KAAK,EAAE,CAEnB,MAAO,WAAM,CACTd,WAAW,CAACe,KAAK,EAAE,CACvB,CAAC,CACL,CAAC,CAAE,EAAE,CAAC,CAEN,mBACI,kCACI,mBAAIjB,aAAa,EAAK,EACpB,CAEd,CAAC,CAED,cAAeD,aAAY"},"metadata":{},"sourceType":"module","externalDependencies":[]}